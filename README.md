# Breakout Reinforcement Learning Implementations

Welcome to the Breakout Reinforcement Learning Implementations repository! This project includes various implementations of Reinforcement Learning algorithms applied to the classic Breakout game environment. Whether you are a beginner or an experienced practitioner, you'll find useful resources and detailed instructions to help you get started with these cutting-edge models.

## üöÄ Directory Structure

The repository is organized into the following directories, each containing a specific approach to solving Breakout using different RL algorithms:

- **`BreakOut_base`**: 
  - *Description*: Base implementation of the Deep Q-Network (DQN) for the Breakout game.
  - *Details*: Find more information in the specific README in this directory.

- **`BreakOut_sb3_A2C`**: 
  - *Description*: Implementation of the Advantage Actor-Critic (A2C) algorithm using Stable Baselines 3.
  - *Details*: Detailed instructions are provided in the corresponding README.

- **`BreakOut_sb3_PPO`**: 
  - *Description*: Proximal Policy Optimization (PPO) approach using Stable Baselines 3.
  - *Details*: Refer to the README within for setup and usage instructions.

- **`Breakout_sb3_DQN`**: 
  - *Description*: Implementation of DQN using Stable Baselines 3.
  - *Details*: The README in this folder will guide you through the necessary steps for training and testing.

## üèÅ Getting Started

To get started with any of the implementations:

1. **Navigate** to the respective directory.
2. **Follow** the instructions provided in its README file.

## üì¶ Installation

Ensure Python 3.x is installed along with the following dependencies, which are common across all implementations:

```bash
pip install -r requirements.txt
```

## üéÆ Usage

1. **Clone** this repository:
    ```bash
    git clone https://github.com/Neilus03/DRL_comparative_study
    cd Breakout-RL-Implementations
    ```

2. **Navigate** to the desired implementation directory, e.g., for PPO:
    ```bash
    cd BreakOut_sb3_PPO
    ```
    
3. **Configure** the config.py file to adjust the model training, the wandb account and the saving model options.

4. **Execute** the `train.py` to run the model.


## üë• Contributing

We welcome contributions! If you have suggestions or improvements, feel free to create a pull request or open an issue.


## üìß Contact

For any questions or inquiries, please reach out to 

[Daniel Vidal](https://www.linkedin.com/in/daniel-alejandro-vidal-guerra-21386b266/).
[Neil de la Fuente](https://www.linkedin.com/in/neil-de-la-fuente/)

---

Thank you for visiting! We hope you find this repository useful and educational. Happy coding and happy learning! üéâ

---
